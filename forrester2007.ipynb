{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from multifidelityfunctions import oneDimensional as OD\n",
    "from multiLevelCoSurrogates import CandidateArchive, Surrogate, HierarchicalSurrogate, MultiFidelityBO, create_random_sample_set\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating the example plot in [Forrester2007 (Multi-fidelity optimization via surrogate modelling)](https://royalsocietypublishing.org/doi/full/10.1098/rspa.2007.1900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function in question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = np.linspace(start=0,stop=1,num=101).reshape(-1,1)\n",
    "\n",
    "plot_high = OD.high(plot_x)\n",
    "plot_low = OD.low(plot_x)\n",
    "\n",
    "plt.plot(plot_x, plot_high, label='high')\n",
    "plt.plot(plot_x, plot_low, label='low')\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the datapoints selected by the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_x = np.array([0, .4, .6, 1]).reshape(-1,1)\n",
    "low_x = np.linspace(0,1,11).reshape(-1,1)\n",
    "\n",
    "high_y = OD.high(high_x)\n",
    "low_y = OD.low(low_x)\n",
    "\n",
    "\n",
    "line, = plt.plot(plot_x, plot_high, label='high')\n",
    "plt.scatter(high_x, high_y, color=line.get_color())\n",
    "line, = plt.plot(plot_x, plot_low, label='low')\n",
    "plt.scatter(low_x, low_y, color=line.get_color())\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Gaussian Process models for each fidelity exclusively. Low-fidelity is a good fit, high fidelity is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_direct = GaussianProcessRegressor()\n",
    "gp_direct.fit(high_x, high_y)\n",
    "\n",
    "gp_low = GaussianProcessRegressor()\n",
    "gp_low.fit(low_x, low_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line, = plt.plot(plot_x, plot_high, label='high')\n",
    "plt.scatter(high_x, high_y, color=line.get_color())\n",
    "line, = plt.plot(plot_x, plot_low, label='low')\n",
    "plt.scatter(low_x, low_y, color=line.get_color())\n",
    "\n",
    "plt.plot(plot_x, gp_direct.predict(plot_x), label='high-fit GP')\n",
    "plt.plot(plot_x, gp_low.predict(plot_x), label='low-fit GP')\n",
    "\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-Kriging formulation is $\\hat{f}_h(x) = \\rho * f_l(x) + \\delta(x)$. <br>\n",
    "$\\hat{f}_h(x)$ is the high-fidelity prediction at $x$<br>\n",
    "$\\rho$ is a scaling factor<br>\n",
    "$f_l(x)$ is a low-fidelity information input (either actual or another model) at $x$<br>\n",
    "$\\delta(x)$ is a prediction for the difference between $f_h(x)$ and $\\rho * f_l(x)$<br>\n",
    "\n",
    "$\\rho$ is calculated as $1 / (1/n)\\Sigma_{i=1}^n f_h(x_i) / f_l(x_i)$, i.e. `1/mean(f_high(x_high) / f_low(x_high))` with `x_high` being all input for which we have high-fidelity outcomes.\n",
    "\n",
    "Here we start by plotting just the parts of this equation.<br>\n",
    "In this example, there is an explicit scaling factor of __2__ between high and low fidelity that is seen to be easily captured by the difference model $\\delta(x)$/`gp_diff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_at_high = np.array(OD.low([x for x in high_x])).reshape(-1,1)\n",
    "scale = 1/np.mean(high_y / low_at_high)\n",
    "\n",
    "diff_x = high_x\n",
    "diff_y = np.array([(OD.high(x) - scale*OD.low(x)) for x in diff_x])\n",
    "\n",
    "gp_diff = GaussianProcessRegressor()\n",
    "gp_diff.fit(diff_x, diff_y)\n",
    "\n",
    "line, = plt.plot(plot_x, plot_high, label='high')\n",
    "plt.scatter(high_x, high_y, color=line.get_color())\n",
    "line, = plt.plot(plot_x, plot_low, label='low')\n",
    "plt.scatter(low_x, low_y, color=line.get_color())\n",
    "\n",
    "plt.plot(plot_x, gp_direct.predict(plot_x), label='high-fit GP')\n",
    "plt.plot(plot_x, gp_low.predict(plot_x), label='low-fit GP')\n",
    "\n",
    "plt.plot(plot_x, plot_high - plot_low, label='diff')\n",
    "plt.plot(plot_x, gp_diff.predict(plot_x), label='scaled diff-fit GP')\n",
    "\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with the actual co-kriging prediction plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_y = lambda x: scale*gp_low.predict(x) + gp_diff.predict(x)\n",
    "\n",
    "line, = plt.plot(plot_x, plot_high, label='high')\n",
    "plt.scatter(high_x, high_y, color=line.get_color())\n",
    "line, = plt.plot(plot_x, plot_low, label='low')\n",
    "plt.scatter(low_x, low_y, color=line.get_color())\n",
    "\n",
    "plt.plot(plot_x, gp_direct.predict(plot_x), label='high-fit GP')\n",
    "plt.plot(plot_x, gp_low.predict(plot_x), label='low-fit GP')\n",
    "\n",
    "# plt.plot(plot_x, plot_high - plot_low, label='diff')\n",
    "# plt.plot(plot_x, gp_diff.predict(plot_x.reshape(-1,1)), label='diff-fit GP')\n",
    "\n",
    "plt.plot(plot_x, co_y(plot_x), label='co-kriging')\n",
    "\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct construction with (Hierarchical)Surrogate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating the same plot as above using our own (Hierarchical)Surrogate interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without normalization by Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_x = np.linspace(0,1,11).reshape((-1,1))\n",
    "high_x = low_x[[0,4,6,10]].reshape((-1,1))\n",
    "\n",
    "archive = CandidateArchive(ndim=1, fidelities=['high', 'low', 'high-low'])\n",
    "archive.addcandidates(low_x, OD.low(low_x), fidelity='low')\n",
    "archive.addcandidates(high_x, OD.high(high_x), fidelity='high')\n",
    "\n",
    "surr_high = Surrogate.fromname('Kriging', archive, fidelity='high', normalized=False)\n",
    "surr_low = Surrogate.fromname('Kriging', archive, fidelity='low', normalized=False)\n",
    "surr_hier = HierarchicalSurrogate('Kriging', surr_low, archive, ['high', 'low'], normalized=False)\n",
    "\n",
    "surr_high.train()\n",
    "surr_low.train()\n",
    "surr_hier.train()\n",
    "\n",
    "# Plotting\n",
    "x = np.linspace(start=0,stop=1,num=101).reshape(-1,1)\n",
    "plt.plot(x, OD.high(x), label='high')\n",
    "plt.plot(x, OD.low(x), label='low')\n",
    "plt.plot(x, surr_high.predict(x), label='high-fit GP')\n",
    "plt.plot(x, surr_low.predict(x), label='low-fit GP')\n",
    "plt.plot(x, surr_hier.predict(x), label='co-kriging')\n",
    "plt.legend(loc=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With normalization by Surrogate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to show that the normalization is correctly implemented.<br>\n",
    "Because of the values in this example, it's not really needed, but if the results at least don't get worse in this case, it's probably correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_x = np.linspace(0,1,11).reshape((-1,1))\n",
    "high_x = low_x[[0,4,6,10]].reshape((-1,1))\n",
    "\n",
    "archive = CandidateArchive(ndim=1, fidelities=['high', 'low', 'high-low'])\n",
    "archive.addcandidates(low_x, OD.low(low_x), fidelity='low')\n",
    "archive.addcandidates(high_x, OD.high(high_x), fidelity='high')\n",
    "\n",
    "surr_high = Surrogate.fromname('Kriging', archive, fidelity='high', normalized=True)\n",
    "surr_low = Surrogate.fromname('Kriging', archive, fidelity='low', normalized=True)\n",
    "surr_hier = HierarchicalSurrogate('Kriging', surr_low, archive, ['high', 'low'], normalized=True)\n",
    "\n",
    "surr_high.train()\n",
    "surr_low.train()\n",
    "surr_hier.train()\n",
    "\n",
    "# Plotting\n",
    "x = np.linspace(start=0,stop=1,num=101).reshape(-1,1)\n",
    "plt.plot(x, OD.high(x), label='high')\n",
    "plt.plot(x, OD.low(x), label='low')\n",
    "plt.plot(x, surr_high.predict(x), label='high-fit GP')\n",
    "plt.plot(x, surr_low.predict(x), label='low-fit GP')\n",
    "plt.plot(x, surr_hier.predict(x), label='co-kriging')\n",
    "plt.legend(loc=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct construction with MultiFidelityBO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating the same plot again with the MultiFidelityBO (Bayesian Optimization) interface.<br>\n",
    "This interface automatically creates a full set of hierarchical models for any number of fidelities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_x = np.linspace(0,1,11).reshape((-1,1))\n",
    "high_x = low_x[[0,4,6,10]].reshape((-1,1))\n",
    "\n",
    "archive = CandidateArchive(ndim=1, fidelities=['high', 'low', 'high-low'])\n",
    "archive.addcandidates(low_x, OD.low(low_x), fidelity='low')\n",
    "archive.addcandidates(high_x, OD.high(high_x), fidelity='high')\n",
    "\n",
    "mfbo = MultiFidelityBO(OD, archive)\n",
    "\n",
    "# Plotting\n",
    "x = np.linspace(start=0,stop=1,num=101).reshape(-1,1)\n",
    "plt.plot(x, OD.high(x), label='high')\n",
    "plt.plot(x, OD.low(x), label='low')\n",
    "plt.plot(x, mfbo.direct_models['high'].predict(x), label='high-fit GP')\n",
    "plt.plot(x, mfbo.models['low'].predict(x), label='low-fit GP')\n",
    "plt.plot(x, mfbo.models['high'].predict(x), label='co-kriging')\n",
    "plt.legend(loc=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade-off heatmap: number of high- vs. low-fidelity points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
