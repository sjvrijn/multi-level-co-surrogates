{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:21:43.502120Z",
     "start_time": "2018-07-09T12:21:38.079108Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(linewidth=1000, edgeitems=30)\n",
    "pd.set_option('display.max_columns', 60)\n",
    "pd.set_option('display.width', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:21:43.517111Z",
     "start_time": "2018-07-09T12:21:43.506116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some StackOverflow magic to enable importing of local module\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:21:43.534100Z",
     "start_time": "2018-07-09T12:21:43.521110Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiLevelCoSurrogates.local import base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:21:43.699000Z",
     "start_time": "2018-07-09T12:21:43.538097Z"
    }
   },
   "outputs": [],
   "source": [
    "records = ['_ei_records.csv', '_ucb_records.csv',]\n",
    "\n",
    "print(os.listdir(base_dir))\n",
    "\n",
    "df = pd.read_csv(base_dir+records[0], index_col='index')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:21:47.231099Z",
     "start_time": "2018-07-09T12:21:43.703996Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(by=['which_model', 'fidelity'])\n",
    "\n",
    "n_cols = min(len(grouped), 3)\n",
    "n_rows = int(np.ceil(len(grouped)/n_cols))\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12,4*n_rows))\n",
    "\n",
    "for ax, group in zip(axes.flatten(), grouped):\n",
    "    name, sub_df = group\n",
    "    sub_df = sub_df.groupby(by='iteration')[['mse_high', 'mse_low', 'mse_hier', 'mse_low_on_high']]\n",
    "    means = sub_df.mean()\n",
    "    stds = sub_df.std()\n",
    "    means.plot(ax=ax)\n",
    "    \n",
    "    low_bounds, high_bounds = means.values.T - stds.values.T*1.96, means.values.T + stds.values.T*1.96\n",
    "    for low, high, color in zip(low_bounds, high_bounds, ['C0', 'C1', 'C2', 'C3']):\n",
    "        ax.fill_between(means.index, low, high, color=color, alpha=.2)\n",
    "\n",
    "    ax.set_title('acq on {}, {} fidelity updated'.format(*name))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show the raw MSE values (and 95% CI) for the three cases using the 'Expected Improvement' acquisition function. In the last plot, only the high fidelity model is updated, so the other values are constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:22:36.276065Z",
     "start_time": "2018-07-09T12:22:36.183123Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_normalized(df, axes=None):\n",
    "\n",
    "    grouped = df.groupby(by=['which_model', 'fidelity'])\n",
    "    mse_names = ['mse_high', 'mse_low', 'mse_hier', 'mse_low_on_high']\n",
    "\n",
    "    if axes is None:\n",
    "        n_cols = min(len(grouped), 3)\n",
    "        n_rows = int(np.ceil(len(grouped)/n_cols))\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(12,4*n_rows))\n",
    "    \n",
    "    for ax, group in zip(axes.flatten(), grouped):\n",
    "        name, sub_df = group\n",
    "\n",
    "        # Separate out the MSE values after initial training to use as reference\n",
    "        num_iters = len(sub_df['iteration'].unique())\n",
    "        first_rows = sub_df.loc[0::num_iters,mse_names].values\n",
    "\n",
    "        # Get all values and reshape without copying s.t. the iterations are a separate dimension\n",
    "        values = sub_df.loc[:,mse_names].values\n",
    "        old_shape = values.shape\n",
    "        new_shape = old_shape[0]//num_iters, num_iters, len(mse_names)\n",
    "        values.shape = new_shape\n",
    "\n",
    "        # Now we can use numpy's internal broadcasting for efficient division, and return the old shape afterwards\n",
    "        new_values = values / first_rows[:,None,:]\n",
    "        new_values.shape = old_shape\n",
    "\n",
    "        # Finally the values are returned to the dataframe and plotted\n",
    "        sub_df.loc[:,mse_names] = new_values\n",
    "        sub_df = sub_df.groupby(by='iteration')[mse_names]\n",
    "        means = sub_df.mean()\n",
    "        stds = sub_df.std()\n",
    "        \n",
    "        means.plot(ax=ax)\n",
    "        \n",
    "        # low_bounds, high_bounds = means.values.T - stds.values.T*1.96, means.values.T + stds.values.T*1.96\n",
    "        low_bounds, high_bounds = sub_df.quantile(.05).values.T, sub_df.quantile(.95).values.T\n",
    "        \n",
    "        for low, high, color in zip(low_bounds, high_bounds, ['C0', 'C1', 'C2', 'C3']):\n",
    "            ax.fill_between(means.index, low, high, color=color, alpha=.2)\n",
    "        \n",
    "        ax.axhline(y=1.0, color='black', alpha=0.5)\n",
    "        ax.set_title('acq on {}, {} fidelity updated'.format(*name))\n",
    "#         ax.set_ylim([0,2])\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots are all normalized to a starting MSE of '1.0', which is comparable as they are all initialized with just 3 high fidelity points and 5 low fidelity points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:22:40.145292Z",
     "start_time": "2018-07-09T12:22:36.282062Z"
    }
   },
   "outputs": [],
   "source": [
    "print(records[0])\n",
    "plot_normalized(pd.read_csv(base_dir+records[0], index_col='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:22:43.254619Z",
     "start_time": "2018-07-09T12:22:40.151283Z"
    }
   },
   "outputs": [],
   "source": [
    "print(records[1])\n",
    "plot_normalized(pd.read_csv(base_dir+records[1], index_col='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(base_dir+records[0], index_col='index')\n",
    "mse_names = ['mse_high', 'mse_low', 'mse_hier', 'mse_low_on_high']\n",
    "\n",
    "# Separate out the MSE values after initial training to use as reference\n",
    "num_iters = len(df['iteration'].unique())\n",
    "first_rows = df.loc[0::num_iters,mse_names].values\n",
    "\n",
    "# Get all values and reshape without copying s.t. the iterations are a separate dimension\n",
    "values = df.loc[:,mse_names].values\n",
    "old_shape = values.shape\n",
    "new_shape = old_shape[0]//num_iters, num_iters, len(mse_names)\n",
    "values.shape = new_shape\n",
    "\n",
    "# Now we can use numpy's internal broadcasting for efficient division, and return the old shape afterwards\n",
    "new_values = values / first_rows[:,None,:]\n",
    "new_values.shape = old_shape\n",
    "\n",
    "# Finally the values are returned to the dataframe and plotted\n",
    "df.loc[:,mse_names] = new_values\n",
    "\n",
    "\n",
    "\n",
    "b3hier = df[df['which_model'] == 'hierarchical']\n",
    "b3hier = b3hier[b3hier['fidelity'] == 'both 3']\n",
    "b3hier = b3hier.groupby(by='iteration')[['mse_high', 'mse_hier']]\n",
    "\n",
    "highhigh = df[df['which_model'] == 'high']\n",
    "highhigh = highhigh[highhigh['fidelity'] == 'high']\n",
    "highhigh = highhigh.groupby(by='iteration')['mse_high']\n",
    "\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "plt.plot(b3hier.mean()['mse_high'], label='both 3, hierarchical: mse_high')\n",
    "plt.plot(b3hier.mean()['mse_hier'], label='both 3, hierarchical: mse_hier')\n",
    "plt.plot(np.repeat(highhigh.mean().values, 3), label='high, high: mse_high')\n",
    "\n",
    "low_bounds, high_bounds = b3hier.quantile(.05).values.T, b3hier.quantile(.95).values.T\n",
    "plt.fill_between(b3hier.mean().index, low_bounds[0], high_bounds[0], color='C0', alpha=.2)\n",
    "plt.fill_between(b3hier.mean().index, low_bounds[1], high_bounds[1], color='C1', alpha=.2)\n",
    "\n",
    "low_bounds, high_bounds = highhigh.quantile(.05).values.T, highhigh.quantile(.95).values.T\n",
    "plt.fill_between(np.arange(len(low_bounds))*3, low_bounds, high_bounds, color='C2', alpha=.2)\n",
    "\n",
    "plt.axhline(y=1.0, alpha=0.33, color='black')\n",
    "plt.legend(loc=0)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we focus on the best performing cases: acquisition function (expected improvement) on high fidelity only and hierarchical prediction.\n",
    "\n",
    "In the above plot, the 'update high fidelity based on high fidelity acquisition function' plot has been stretched by a factor of 3 to match up with the number of high fidelity evaluations in the 'both every 3rd on hierarchical acquisition function' case.\n",
    "It can be seen that, according to MSE, the hierarchical model (mse_hier) is actually better than the high fidelity model, with both of them ourperforming the single-fidelity (high, high) case.\n",
    "\n",
    "The shaded areas show the 5th to 95th percentile of the MSE results. The spread is more varied for the bi-fidelity case at the start, but seems to become more stable towards the end of the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
